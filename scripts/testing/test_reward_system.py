#!/usr/bin/env python3
"""
æµ‹è¯•æ–°çš„å¥–åŠ±å‡½æ•°ç³»ç»Ÿ

éªŒè¯:
1. ç¯å¢ƒèƒ½å¦æ­£å¸¸åŠ è½½
2. å¥–åŠ±å‡½æ•°æ˜¯å¦æ­£å¸¸è®¡ç®—
3. ç›®æ ‡ç‚¹æ˜¯å¦æ­£ç¡®ç”Ÿæˆ
4. ç»ˆæ­¢æ¡ä»¶æ˜¯å¦æœ‰æ•ˆ
"""

import argparse
import torch

# Isaac Lab
from isaaclab.app import AppLauncher

# æ·»åŠ argparseå‚æ•°
parser = argparse.ArgumentParser(description="æµ‹è¯•ROSOrinå¥–åŠ±å‡½æ•°ç³»ç»Ÿ")
parser.add_argument("--num_envs", type=int, default=4, help="å¹¶è¡Œç¯å¢ƒæ•°é‡")

# AppLauncher (ä¼šè‡ªåŠ¨æ·»åŠ --headlessç­‰å‚æ•°)
AppLauncher.add_app_launcher_args(parser)
args_cli = parser.parse_args()
app_launcher = AppLauncher(args_cli)
simulation_app = app_launcher.app

# å¯¼å…¥Isaac Labæ¨¡å— (å¿…é¡»åœ¨AppLauncherä¹‹å)
import isaaclab.sim as sim_utils
from isaaclab.envs import ManagerBasedRLEnv

# å¯¼å…¥ç¯å¢ƒé…ç½®
from rosorin_env_cfg import ROSOrinEnvCfg

def main():
    """æµ‹è¯•ä¸»å‡½æ•°"""
    
    print("\n" + "="*80)
    print("  ROSOrin å¥–åŠ±å‡½æ•°ç³»ç»Ÿæµ‹è¯•")
    print("="*80)
    
    # åˆ›å»ºç¯å¢ƒé…ç½®
    env_cfg = ROSOrinEnvCfg()
    env_cfg.scene.num_envs = args_cli.num_envs
    env_cfg.episode_length_s = 10.0  # çŸ­episodeç”¨äºæµ‹è¯•
    
    print(f"\nğŸ“Š ç¯å¢ƒé…ç½®:")
    print(f"  - å¹¶è¡Œç¯å¢ƒæ•°: {env_cfg.scene.num_envs}")
    print(f"  - Episodeé•¿åº¦: {env_cfg.episode_length_s}ç§’")
    print(f"  - æ§åˆ¶é¢‘ç‡: {1.0 / (env_cfg.sim.dt * env_cfg.decimation):.0f} Hz")
    
    # åˆ›å»ºç¯å¢ƒ
    print("\nğŸ”§ åˆ›å»ºç¯å¢ƒ...")
    env = ManagerBasedRLEnv(cfg=env_cfg)
    
    # æ‰“å°å¥–åŠ±å‡½æ•°é…ç½®
    print(f"\nğŸ å¥–åŠ±å‡½æ•°ä½“ç³»:")
    print("  (å·²ä»ç¯å¢ƒmanagerè¾“å‡ºä¸­ç¡®è®¤,åŒ…å«8ä¸ªå¥–åŠ±é¡¹)")
    
    # æ‰“å°ç»ˆæ­¢æ¡ä»¶
    print(f"\nğŸ›‘ ç»ˆæ­¢æ¡ä»¶:")
    print("  (å·²ä»ç¯å¢ƒmanagerè¾“å‡ºä¸­ç¡®è®¤,åŒ…å«3ä¸ªç»ˆæ­¢æ¡ä»¶)")
    
    # æ‰“å°è§‚æµ‹ç©ºé—´
    print(f"\nğŸ‘ï¸  è§‚æµ‹ç©ºé—´:")
    print("  (å·²ä»ç¯å¢ƒmanagerè¾“å‡ºä¸­ç¡®è®¤, æ€»ç»´åº¦: 76813)")
    print("  åŒ…å«: æœ¬ä½“æ„ŸçŸ¥(10) + ç›®æ ‡ä¿¡æ¯(3) + RGB(57600) + Depth(19200)")
    
    # Resetç¯å¢ƒ
    print(f"\nğŸ”„ é‡ç½®ç¯å¢ƒ...")
    obs_dict, _ = env.reset()
    obs = obs_dict["policy"]
    
    # æ£€æŸ¥ç›®æ ‡ç‚¹æ˜¯å¦ç”Ÿæˆ
    if hasattr(env, 'goal_positions'):
        print(f"\nğŸ¯ ç›®æ ‡ç‚¹å·²ç”Ÿæˆ:")
        for i in range(min(3, env.num_envs)):  # åªæ˜¾ç¤ºå‰3ä¸ª
            goal = env.goal_positions[i, :2]
            robot_pos = env.scene.articulations["robot"].data.root_pos_w[i, :2]
            distance = torch.norm(goal - robot_pos).item()
            print(f"  Env {i}: ç›®æ ‡({goal[0]:.2f}, {goal[1]:.2f}) | è·ç¦»: {distance:.2f}m")
    else:
        print("\nâš ï¸  è­¦å‘Š: ç›®æ ‡ç‚¹æœªç”Ÿæˆ!")
    
    # è¿è¡Œå‡ æ­¥æµ‹è¯•å¥–åŠ±è®¡ç®—
    print(f"\nğŸƒ è¿è¡Œæµ‹è¯• (50æ­¥)...")
    
    total_rewards = torch.zeros(env.num_envs, device=env.device)
    
    for step in range(50):
        # éšæœºåŠ¨ä½œ (4ä¸ªè½®é€Ÿæ§åˆ¶)
        actions = torch.rand(env.num_envs, 4, device=env.device) * 2 - 1  # [-1, 1]
        
        # æ‰§è¡Œ
        obs_dict, rewards, dones, truncated, infos = env.step(actions)
        
        # ç´¯ç§¯å¥–åŠ±
        total_rewards += rewards
        
        # æ£€æŸ¥ç»ˆæ­¢
        if dones.any():
            done_envs = dones.nonzero(as_tuple=True)[0]
            print(f"  Step {step}: ç¯å¢ƒ {done_envs.tolist()} ç»ˆæ­¢")
    
    # æ‰“å°ç»“æœ
    print(f"\nğŸ“ˆ æµ‹è¯•ç»“æœç»Ÿè®¡:")
    print(f"  å¹³å‡æ€»å¥–åŠ±: {total_rewards.mean().item():.3f}")
    print(f"  å¥–åŠ±æ ‡å‡†å·®: {total_rewards.std().item():.3f}")
    print(f"  æœ€å¤§å¥–åŠ±: {total_rewards.max().item():.3f}")
    print(f"  æœ€å°å¥–åŠ±: {total_rewards.min().item():.3f}")
    
    # å…³é—­ç¯å¢ƒ
    env.close()
    
    print("\n" + "="*80)
    print("âœ… æµ‹è¯•å®Œæˆ!")
    print("="*80 + "\n")


if __name__ == "__main__":
    # è¿è¡Œæµ‹è¯•
    main()
    
    # å…³é—­æ¨¡æ‹Ÿå™¨
    simulation_app.close()
