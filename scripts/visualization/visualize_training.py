#!/usr/bin/env python3
"""
å¯è§†åŒ–æµ‹è¯•è„šæœ¬ - è§‚å¯ŸROSOrinæœºå™¨äººå¯¼èˆªè®­ç»ƒè¿‡ç¨‹

åœ¨Isaac Sim GUIä¸­å¯è§†åŒ–æ˜¾ç¤º:
- æœºå™¨äººè¿åŠ¨
- ç›®æ ‡ç‚¹ä½ç½®
- å¥–åŠ±å®æ—¶å˜åŒ–
"""

import argparse
import torch
import time

# Isaac Lab
from isaaclab.app import AppLauncher

parser = argparse.ArgumentParser(description="å¯è§†åŒ–ROSOrinå¯¼èˆªè®­ç»ƒ")
parser.add_argument("--num_envs", type=int, default=2, help="å¹¶è¡Œç¯å¢ƒæ•°é‡(å»ºè®®1-4)")

# AppLauncher (è‡ªåŠ¨æ·»åŠ --headlessç­‰å‚æ•°)
AppLauncher.add_app_launcher_args(parser)
args_cli = parser.parse_args()

# å¼ºåˆ¶ç¦ç”¨headlessæ¨¡å¼ä»¥æ˜¾ç¤ºGUI
args_cli.headless = False

app_launcher = AppLauncher(args_cli)
simulation_app = app_launcher.app

# å¯¼å…¥Isaac Labæ¨¡å—
from isaaclab.envs import ManagerBasedRLEnv
from rosorin_env_cfg import ROSOrinEnvCfg

def main():
    """å¯è§†åŒ–æµ‹è¯•ä¸»å‡½æ•°"""
    
    print("\n" + "="*80)
    print("  ğŸ¬ ROSOrin å¯è§†åŒ–å¯¼èˆªæµ‹è¯•")
    print("="*80)
    
    # åˆ›å»ºç¯å¢ƒé…ç½®
    env_cfg = ROSOrinEnvCfg()
    env_cfg.scene.num_envs = args_cli.num_envs
    env_cfg.episode_length_s = 20.0  # 20ç§’episodes
    
    print(f"\nğŸ“Š é…ç½®:")
    print(f"  ç¯å¢ƒæ•°é‡: {env_cfg.scene.num_envs}")
    print(f"  Episode: {env_cfg.episode_length_s}ç§’")
    print(f"  å¥–åŠ±å‡½æ•°: 8é¡¹")
    print(f"  ç»ˆæ­¢æ¡ä»¶: 3é¡¹")
    
    # åˆ›å»ºç¯å¢ƒ
    print(f"\nğŸ”§ åˆ›å»ºç¯å¢ƒ (GUIæ¨¡å¼)...")
    print(f"  æç¤º: çª—å£å°†åœ¨å‡ ç§’åæ‰“å¼€...")
    
    env = ManagerBasedRLEnv(cfg=env_cfg)
    
    print(f"\nâœ… ç¯å¢ƒå·²åˆ›å»º! Isaac Simçª—å£åº”è¯¥å·²æ˜¾ç¤º")
    print(f"\nğŸ® æ§åˆ¶è¯´æ˜:")
    print(f"  - é¼ æ ‡å·¦é”®æ‹–åŠ¨: æ—‹è½¬è§†è§’")
    print(f"  - é¼ æ ‡ä¸­é”®æ‹–åŠ¨: å¹³ç§»è§†è§’")
    print(f"  - é¼ æ ‡æ»šè½®: ç¼©æ”¾")
    print(f"  - æŒ‰ 'P' é”®: æš‚åœ/ç»§ç»­æ¨¡æ‹Ÿ")
    
    # Resetç¯å¢ƒ
    print(f"\nğŸ”„ é‡ç½®ç¯å¢ƒ...")
    obs_dict, _ = env.reset()
    
    # æ˜¾ç¤ºç›®æ ‡ç‚¹ä¿¡æ¯
    if hasattr(env, 'goal_positions'):
        print(f"\nğŸ¯ ç›®æ ‡ç‚¹å·²ç”Ÿæˆ:")
        for i in range(env.num_envs):
            goal = env.goal_positions[i, :2]
            robot_pos = env.scene.articulations["robot"].data.root_pos_w[i, :2]
            distance = torch.norm(goal - robot_pos).item()
            print(f"  Env {i}: ç›®æ ‡({goal[0]:.2f}, {goal[1]:.2f}) | è·ç¦»: {distance:.2f}m")
    
    # è¿è¡Œæ¨¡æ‹Ÿ
    print(f"\nğŸƒ å¼€å§‹æ¨¡æ‹Ÿ (è¿è¡Œ200æ­¥)...")
    print(f"  è§‚å¯Ÿ:")
    print(f"  - æœºå™¨äººå¦‚ä½•å‘ç›®æ ‡ç‚¹ç§»åŠ¨")
    print(f"  - å¥–åŠ±å€¼å˜åŒ–")
    print(f"  - å§¿æ€ç¨³å®šæ€§")
    
    episode_rewards = torch.zeros(env.num_envs, device=env.device)
    step_count = 0
    max_steps = 200
    
    for step in range(max_steps):
        # ç®€å•çš„å¯¼èˆªç­–ç•¥ï¼šæœç›®æ ‡æ–¹å‘ç§»åŠ¨ (æµ‹è¯•å¯è§†åŒ–)
        if hasattr(env, 'goal_positions'):
            # è·å–æœºå™¨äººå½“å‰ä½ç½®å’Œæœå‘
            robot_pos = env.scene.articulations["robot"].data.root_pos_w[:, :2]  # (N, 2)
            robot_quat = env.scene.articulations["robot"].data.root_quat_w  # (N, 4)
            
            # è®¡ç®—æœå‘ç›®æ ‡çš„æ–¹å‘å‘é‡
            goal_vec = env.goal_positions[:, :2] - robot_pos  # (N, 2)
            goal_distance = torch.norm(goal_vec, dim=-1, keepdim=True)  # (N, 1)
            goal_dir = goal_vec / (goal_distance + 1e-6)  # (N, 2) å½’ä¸€åŒ–
            
            # æå–æœºå™¨äººyawè§’
            # quat = [x, y, z, w], yaw = atan2(2*(w*z + x*y), 1 - 2*(y^2 + z^2))
            yaw = torch.atan2(
                2.0 * (robot_quat[:, 3] * robot_quat[:, 2] + robot_quat[:, 0] * robot_quat[:, 1]),
                1.0 - 2.0 * (robot_quat[:, 1]**2 + robot_quat[:, 2]**2)
            )  # (N,)
            robot_dir = torch.stack([torch.cos(yaw), torch.sin(yaw)], dim=-1)  # (N, 2)
            
            # è®¡ç®—è½¬å‘è¯¯å·® (ç‚¹ç§¯åˆ¤æ–­æ˜¯å¦å¯¹é½)
            alignment = (robot_dir * goal_dir).sum(dim=-1)  # (N,) èŒƒå›´[-1, 1]
            cross = robot_dir[:, 0] * goal_dir[:, 1] - robot_dir[:, 1] * goal_dir[:, 0]  # å‰ç§¯åˆ¤æ–­å·¦å³
            
            # æ„é€ ç®€å•çš„éº¦å…‹çº³å§†è½®æ§åˆ¶ (4ä¸ªè½®å­é€Ÿåº¦)
            # å‰è¿›é€Ÿåº¦: åŸºäºè·ç¦»å’Œå¯¹é½åº¦
            forward_vel = torch.clamp(goal_distance.squeeze(-1) * 0.3, 0, 1.0) * (alignment + 1.0) / 2.0
            # è½¬å‘é€Ÿåº¦: åŸºäºå‰ç§¯
            turn_vel = torch.clamp(cross * 0.8, -0.5, 0.5)
            
            # éº¦å…‹çº³å§†è½®å·®é€Ÿ: [å·¦å‰, å³å‰, å·¦å, å³å]
            actions = torch.stack([
                forward_vel + turn_vel,  # å·¦å‰
                forward_vel - turn_vel,  # å³å‰
                forward_vel + turn_vel,  # å·¦å
                forward_vel - turn_vel,  # å³å
            ], dim=-1)  # (N, 4)
        else:
            # å¦‚æœæ²¡æœ‰ç›®æ ‡ï¼Œä½¿ç”¨æ›´å¤§çš„éšæœºåŠ¨ä½œæµ‹è¯•
            actions = (torch.rand(env.num_envs, 4, device=env.device) - 0.5) * 1.5  # èŒƒå›´ [-0.75, 0.75]
        
        # æ‰§è¡Œ
        obs_dict, rewards, dones, truncated, infos = env.step(actions)
        
        episode_rewards += rewards
        step_count += 1
        
        # æ¯20æ­¥æ‰“å°ä¸€æ¬¡çŠ¶æ€
        if (step + 1) % 20 == 0:
            print(f"\n  Step {step+1}/{max_steps}:")
            print(f"    å¹³å‡å¥–åŠ±: {episode_rewards.mean().item():.3f}")
            print(f"    æœ€å¤§å¥–åŠ±: {episode_rewards.max().item():.3f}")
            
            # æ˜¾ç¤ºè·ç¦»å˜åŒ–
            if hasattr(env, 'goal_positions'):
                distances = torch.norm(
                    env.scene.articulations["robot"].data.root_pos_w[:, :2] - env.goal_positions[:, :2],
                    dim=-1
                )
                print(f"    å¹³å‡è·ç¦»ç›®æ ‡: {distances.mean().item():.2f}m")
        
        # æ£€æŸ¥ç»ˆæ­¢
        if dones.any():
            done_envs = dones.nonzero(as_tuple=True)[0]
            print(f"\n  âš ï¸  ç¯å¢ƒ {done_envs.tolist()} ç»ˆæ­¢ (å¯èƒ½åˆ°è¾¾ç›®æ ‡æˆ–å€¾è¦†)")
            # Resetç»ˆæ­¢çš„ç¯å¢ƒ
            env.reset(env_ids=done_envs)
        
        # ç¨å¾®å»¶è¿Ÿä»¥ä¾¿è§‚å¯Ÿ
        time.sleep(0.02)  # 20mså»¶è¿Ÿ
    
    # æœ€ç»ˆç»Ÿè®¡
    print(f"\n" + "="*80)
    print(f"ğŸ“Š æ¨¡æ‹Ÿç»“æŸç»Ÿè®¡:")
    print(f"  æ€»æ­¥æ•°: {step_count}")
    print(f"  å¹³å‡æ€»å¥–åŠ±: {episode_rewards.mean().item():.3f}")
    print(f"  å¥–åŠ±èŒƒå›´: [{episode_rewards.min().item():.3f}, {episode_rewards.max().item():.3f}]")
    
    # ä¿æŒçª—å£æ‰“å¼€
    print(f"\nğŸ’¡ æç¤º:")
    print(f"  - Isaac Simçª—å£å°†ä¿æŒæ‰“å¼€")
    print(f"  - å¯ä»¥ç»§ç»­æ‰‹åŠ¨æ“ä½œç›¸æœºæŸ¥çœ‹åœºæ™¯")
    print(f"  - æŒ‰ Ctrl+C é€€å‡º")
    print(f"="*80 + "\n")
    
    # ç­‰å¾…ç”¨æˆ·å…³é—­
    try:
        print("â¸ï¸  æ¨¡æ‹Ÿå·²æš‚åœã€‚æŒ‰ Ctrl+C é€€å‡º...")
        while True:
            time.sleep(1.0)
    except KeyboardInterrupt:
        print("\nğŸ‘‹ ç”¨æˆ·ä¸­æ–­ï¼Œå…³é—­ç¯å¢ƒ...")
    
    # å…³é—­ç¯å¢ƒ
    env.close()
    print("âœ… ç¯å¢ƒå·²å…³é—­\n")


if __name__ == "__main__":
    # è¿è¡Œå¯è§†åŒ–æµ‹è¯•
    main()
    
    # å…³é—­æ¨¡æ‹Ÿå™¨
    simulation_app.close()
