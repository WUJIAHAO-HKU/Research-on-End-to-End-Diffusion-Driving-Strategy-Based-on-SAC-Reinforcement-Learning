#!/usr/bin/env python3
"""
ä»è®­ç»ƒæ—¥å¿—æ‰‹åŠ¨åˆ›å»ºSACè®­ç»ƒå†å²å›¾è¡¨

åŸºäºç»ˆç«¯è¾“å‡ºçš„è®­ç»ƒè¿›åº¦æ•°æ®
"""

import matplotlib.pyplot as plt
import numpy as np
import json
from pathlib import Path

# ä»ç»ˆç«¯æ—¥å¿—æå–çš„è®­ç»ƒæ•°æ®
training_data = {
    'steps': [10000, 20000, 30000, 40000, 50000, 60000, 70000, 80000, 90000, 100000],
    'avg_rewards': [-8.55, 16.13, 18.06, 6.92, -1.19, 22.04, 22.69, 33.60, 31.34, 8.15],
    'q_values': [-99.60, -76.11, -63.35, -65.78, -70.40, -69.55, -94.61, -108.43, -110.56, -140.58],
    'actor_losses': [99.597, 76.112, 63.349, 65.779, 70.400, 69.552, 94.608, 108.435, 110.558, 140.585],
    'total_episodes': 68,
    'best_step': 80000,
    'best_reward': 33.60
}

def create_training_curves():
    """åˆ›å»ºè®­ç»ƒæ›²çº¿å›¾"""
    
    steps = training_data['steps']
    avg_rewards = training_data['avg_rewards']
    q_values = training_data['q_values']
    actor_losses = training_data['actor_losses']
    
    # åˆ›å»º3è¡Œ1åˆ—çš„å­å›¾
    fig, axes = plt.subplots(3, 1, figsize=(12, 12))
    
    # 1. å¹³å‡å¥–åŠ±æ›²çº¿
    ax = axes[0]
    ax.plot(steps, avg_rewards, 'b-o', linewidth=2, markersize=8, label='Average Reward')
    
    # æ ‡è®°æœ€ä½³ç‚¹
    best_idx = avg_rewards.index(max(avg_rewards))
    ax.plot(steps[best_idx], avg_rewards[best_idx], 'go', markersize=15, 
            label=f'Best Model (step {steps[best_idx]:,}, reward {avg_rewards[best_idx]:.2f})', zorder=5)
    
    # æ ‡è®°ç»ˆç‚¹
    ax.plot(steps[-1], avg_rewards[-1], 'ro', markersize=15,
            label=f'Final Model (step {steps[-1]:,}, reward {avg_rewards[-1]:.2f})', zorder=5)
    
    ax.axhline(y=0, color='gray', linestyle='--', linewidth=1, alpha=0.5)
    ax.set_xlabel('Training Steps', fontsize=12, fontweight='bold')
    ax.set_ylabel('Average Episode Reward', fontsize=12, fontweight='bold')
    ax.set_title('SAC Training Progress - Average Reward', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='best', fontsize=10)
    
    # 2. Qå€¼æ›²çº¿
    ax = axes[1]
    ax.plot(steps, q_values, 'r-s', linewidth=2, markersize=8, label='Q Value Estimate')
    ax.axhline(y=0, color='gray', linestyle='--', linewidth=1, alpha=0.5)
    ax.set_xlabel('Training Steps', fontsize=12, fontweight='bold')
    ax.set_ylabel('Q Value', fontsize=12, fontweight='bold')
    ax.set_title('Critic Q Value Evolution', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='best', fontsize=10)
    
    # 3. Actor Lossæ›²çº¿
    ax = axes[2]
    ax.plot(steps, actor_losses, 'g-^', linewidth=2, markersize=8, label='Actor Loss')
    ax.set_xlabel('Training Steps', fontsize=12, fontweight='bold')
    ax.set_ylabel('Actor Loss', fontsize=12, fontweight='bold')
    ax.set_title('Actor Policy Loss', fontsize=14, fontweight='bold')
    ax.grid(True, alpha=0.3)
    ax.legend(loc='best', fontsize=10)
    
    plt.tight_layout()
    
    # ä¿å­˜å›¾è¡¨
    output_dir = Path('experiments/sac_training/sac_training_20251229_121515')
    save_path = output_dir / 'sac_training_curves.png'
    plt.savefig(save_path, dpi=300, bbox_inches='tight')
    print(f"âœ“ è®­ç»ƒæ›²çº¿å·²ä¿å­˜åˆ°: {save_path}")
    
    # ä¿å­˜JSONæ•°æ®
    json_path = output_dir / 'sac_training_history.json'
    with open(json_path, 'w') as f:
        json.dump(training_data, f, indent=2)
    print(f"âœ“ è®­ç»ƒå†å²æ•°æ®å·²ä¿å­˜åˆ°: {json_path}")
    
    # ç”Ÿæˆåˆ†ææŠ¥å‘Š
    print("\n" + "="*80)
    print("  SACè®­ç»ƒåˆ†ææŠ¥å‘Š")
    print("="*80)
    print(f"æ€»è®­ç»ƒæ­¥æ•°: {steps[-1]:,}")
    print(f"æ€»Episodes: {training_data['total_episodes']}")
    print(f"\nå¥–åŠ±ç»Ÿè®¡:")
    print(f"  åˆå§‹å¥–åŠ±: {avg_rewards[0]:.2f}")
    print(f"  æœ€ä½³å¥–åŠ±: {max(avg_rewards):.2f} (step {steps[avg_rewards.index(max(avg_rewards))]:,})")
    print(f"  æœ€ç»ˆå¥–åŠ±: {avg_rewards[-1]:.2f}")
    print(f"  æå‡å¹…åº¦: {max(avg_rewards) - avg_rewards[0]:.2f} (+{(max(avg_rewards) - avg_rewards[0]) / abs(avg_rewards[0]) * 100:.1f}%)")
    
    print(f"\nå…³é”®å‘ç°:")
    print(f"  âœ… å¿«é€Ÿæå‡: å‰20kæ­¥ä»-8.55æå‡åˆ°+16.13")
    print(f"  ğŸŒŸ å³°å€¼æ€§èƒ½: 80kæ­¥è¾¾åˆ°æœ€ä½³å¥–åŠ±33.60")
    print(f"  âš ï¸ åæœŸé€€åŒ–: 100kæ­¥ä¸‹é™åˆ°8.15ï¼ˆæ€§èƒ½ä¸‹é™76%ï¼‰")
    print(f"  ğŸ“Š Qå€¼æ¶åŒ–: -63.35 â†’ -140.58ï¼ˆè¿‡ä¼°è®¡ç´¯ç§¯ï¼‰")
    
    print(f"\nå»ºè®®:")
    print(f"  1. ä½¿ç”¨80kæ­¥çš„best_model.ptï¼ˆè€Œéfinal_model.ptï¼‰")
    print(f"  2. åæœŸæ€§èƒ½å´©æºƒå¯èƒ½åŸå› ï¼šå­¦ä¹ ç‡è¿‡é«˜ã€Qå€¼è¿‡ä¼°è®¡")
    print(f"  3. æ”¹è¿›æ–¹å‘ï¼šé™ä½åæœŸå­¦ä¹ ç‡ã€å¢åŠ target networkæ›´æ–°é¢‘ç‡")
    print("="*80 + "\n")
    
    plt.show()


if __name__ == "__main__":
    create_training_curves()
