"""
BCæ¨¡å‹è¯„ä¼°è„šæœ¬

åœ¨Isaac Labç¯å¢ƒä¸­è¯„ä¼°è®­ç»ƒå¥½çš„BCç­–ç•¥
"""

import argparse
import torch
import numpy as np
from pathlib import Path
from tqdm import tqdm
import sys
import pickle

from isaaclab.app import AppLauncher

# è§£æå‚æ•°
parser = argparse.ArgumentParser(description="BCæ¨¡å‹è¯„ä¼°")
parser.add_argument("--checkpoint", type=str, required=True, help="æ¨¡å‹checkpointè·¯å¾„")
parser.add_argument("--num_envs", type=int, default=4, help="å¹¶è¡Œç¯å¢ƒæ•°é‡")
parser.add_argument("--num_episodes", type=int, default=20, help="è¯„ä¼°episodeæ•°é‡")
parser.add_argument("--max_steps", type=int, default=500, help="æ¯ä¸ªepisodeæœ€å¤§æ­¥æ•°")
parser.add_argument("--render", action="store_true", help="æ˜¯å¦æ¸²æŸ“")
AppLauncher.add_app_launcher_args(parser)
args = parser.parse_args()

# å¦‚æœä¸æ¸²æŸ“åˆ™headless
if not args.render:
    args.headless = True
    args.enable_cameras = True

# å¯åŠ¨Isaac Sim
app_launcher = AppLauncher(args)
simulation_app = app_launcher.app

# å¯¼å…¥Isaac Lab
from rosorin_env_cfg import ROSOrinEnvCfg
from isaaclab.envs import ManagerBasedRLEnv
import torch.nn as nn


class BCPolicy(nn.Module):
    """BCç­–ç•¥ç½‘ç»œï¼ˆéœ€è¦ä¸è®­ç»ƒæ—¶ä¸€è‡´ï¼‰"""
    
    def __init__(self, obs_dim, action_dim, hidden_dims=[512, 512, 256]):
        super().__init__()
        
        layers = []
        prev_dim = obs_dim
        
        for hidden_dim in hidden_dims:
            layers.extend([
                nn.Linear(prev_dim, hidden_dim),
                nn.ReLU(),
                nn.Dropout(0.1)
            ])
            prev_dim = hidden_dim
        
        layers.append(nn.Linear(prev_dim, action_dim))
        
        self.network = nn.Sequential(*layers)
    
    def forward(self, obs):
        return self.network(obs)


def load_model(checkpoint_path, device):
    """åŠ è½½è®­ç»ƒå¥½çš„æ¨¡å‹"""
    print(f"\nåŠ è½½æ¨¡å‹: {checkpoint_path}")
    
    # ä¿®å¤numpyå…¼å®¹æ€§é—®é¢˜
    # numpy 2.xä¸­ä½¿ç”¨numpy._coreï¼Œä½†åœ¨æŸäº›ç¯å¢ƒä¸­å¯èƒ½ä¸å­˜åœ¨
    # åˆ›å»ºå…¼å®¹å±‚
    if not hasattr(np, '_core'):
        import numpy.core as _core
        sys.modules['numpy._core'] = _core
        sys.modules['numpy._core.multiarray'] = _core.multiarray
        sys.modules['numpy._core.umath'] = _core.umath
    
    try:
        checkpoint = torch.load(checkpoint_path, map_location=device, weights_only=False)
    except ModuleNotFoundError as e:
        if 'numpy._core' in str(e):
            # å¦‚æœä»ç„¶å¤±è´¥ï¼Œä½¿ç”¨pickleç›´æ¥åŠ è½½å¹¶æ‰‹åŠ¨é‡æ˜ å°„
            print("  æ£€æµ‹åˆ°numpyç‰ˆæœ¬å…¼å®¹æ€§é—®é¢˜ï¼Œä½¿ç”¨å…¼å®¹æ¨¡å¼åŠ è½½...")
            
            # åˆ›å»ºè‡ªå®šä¹‰unpickleræ¥é‡æ˜ å°„numpyæ¨¡å—
            class NumpyCompatUnpickler(pickle.Unpickler):
                def find_class(self, module, name):
                    if module.startswith('numpy._core'):
                        module = module.replace('numpy._core', 'numpy.core')
                    return super().find_class(module, name)
            
            with open(checkpoint_path, 'rb') as f:
                checkpoint = NumpyCompatUnpickler(f).load()
        else:
            raise
    
    # è·å–æ¨¡å‹ç»´åº¦ï¼ˆä»å½’ä¸€åŒ–å‚æ•°æ¨æ–­ï¼‰
    obs_mean_data = checkpoint['obs_mean']
    action_mean_data = checkpoint['action_mean']
    
    # ç¡®ä¿æ•°æ®æ˜¯numpyæ•°ç»„
    if isinstance(obs_mean_data, torch.Tensor):
        obs_mean_data = obs_mean_data.cpu().numpy()
    if isinstance(action_mean_data, torch.Tensor):
        action_mean_data = action_mean_data.cpu().numpy()
    
    obs_dim = len(obs_mean_data)
    action_dim = len(action_mean_data)
    
    print(f"  è§‚æµ‹ç»´åº¦: {obs_dim}")
    print(f"  åŠ¨ä½œç»´åº¦: {action_dim}")
    print(f"  è®­ç»ƒEpoch: {checkpoint['epoch']}")
    print(f"  éªŒè¯æŸå¤±: {checkpoint['val_loss']:.6f}")
    
    # ä»checkpointè¯»å–hidden_dimsé…ç½®ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    hidden_dims = checkpoint.get('hidden_dims', [512, 512, 256])
    print(f"  éšè—å±‚ç»´åº¦: {hidden_dims}")
    
    # åˆ›å»ºæ¨¡å‹
    model = BCPolicy(obs_dim, action_dim, hidden_dims=hidden_dims).to(device)
    model.load_state_dict(checkpoint['model_state_dict'])
    model.eval()
    
    # å½’ä¸€åŒ–å‚æ•° - ç¡®ä¿è½¬æ¢ä¸ºnumpyæ•°ç»„
    obs_mean_np = checkpoint['obs_mean']
    obs_std_np = checkpoint['obs_std']
    action_mean_np = checkpoint['action_mean']
    action_std_np = checkpoint['action_std']
    
    # å¦‚æœæ˜¯tensorï¼Œè½¬æ¢ä¸ºnumpy
    if isinstance(obs_mean_np, torch.Tensor):
        obs_mean_np = obs_mean_np.cpu().numpy()
    if isinstance(obs_std_np, torch.Tensor):
        obs_std_np = obs_std_np.cpu().numpy()
    if isinstance(action_mean_np, torch.Tensor):
        action_mean_np = action_mean_np.cpu().numpy()
    if isinstance(action_std_np, torch.Tensor):
        action_std_np = action_std_np.cpu().numpy()
    
    obs_mean = torch.from_numpy(obs_mean_np).to(device)
    obs_std = torch.from_numpy(obs_std_np).to(device)
    action_mean = torch.from_numpy(action_mean_np).to(device)
    action_std = torch.from_numpy(action_std_np).to(device)
    
    return model, obs_mean, obs_std, action_mean, action_std


def evaluate(env, model, obs_mean, obs_std, action_mean, action_std, num_episodes, max_steps):
    """è¯„ä¼°æ¨¡å‹"""
    
    device = next(model.parameters()).device
    num_envs = env.num_envs
    
    # ç»Ÿè®¡ä¿¡æ¯
    episode_rewards = []
    episode_lengths = []
    success_count = 0
    
    episodes_done = 0
    env_episode_rewards = [0.0] * num_envs
    env_episode_lengths = [0] * num_envs
    
    # é‡ç½®ç¯å¢ƒ
    obs_dict, _ = env.reset()
    
    print("\nå¼€å§‹è¯„ä¼°...")
    pbar = tqdm(total=num_episodes, desc="è¯„ä¼°è¿›åº¦")
    
    for step in range(max_steps * num_episodes // num_envs):
        # è·å–è§‚æµ‹
        obs = obs_dict["policy"]
        
        # å¤„ç†infå€¼
        obs = torch.nan_to_num(obs, nan=0.0, posinf=10.0, neginf=0.0)
        
        # å½’ä¸€åŒ–
        obs_normalized = (obs - obs_mean) / obs_std
        
        # é¢„æµ‹åŠ¨ä½œ
        with torch.no_grad():
            actions_normalized = model(obs_normalized)
        
        # åå½’ä¸€åŒ–
        actions = actions_normalized * action_std + action_mean
        
        # æ‰§è¡ŒåŠ¨ä½œ
        obs_dict, rewards, dones, truncated, infos = env.step(actions)
        
        # ç´¯ç§¯ç»Ÿè®¡
        for i in range(num_envs):
            env_episode_rewards[i] += rewards[i].item()
            env_episode_lengths[i] += 1
            
            if dones[i] or truncated[i]:
                episode_rewards.append(env_episode_rewards[i])
                episode_lengths.append(env_episode_lengths[i])
                
                # åˆ¤æ–­æˆåŠŸï¼ˆç®€å•åˆ¤æ–­ï¼šepisodeé•¿åº¦æ¥è¿‘æœ€å¤§æ­¥æ•°ï¼‰
                if env_episode_lengths[i] >= max_steps * 0.8:
                    success_count += 1
                
                episodes_done += 1
                pbar.update(1)
                pbar.set_postfix({
                    'reward': f"{env_episode_rewards[i]:.2f}",
                    'length': env_episode_lengths[i]
                })
                
                env_episode_rewards[i] = 0.0
                env_episode_lengths[i] = 0
                
                if episodes_done >= num_episodes:
                    break
        
        if episodes_done >= num_episodes:
            break
    
    pbar.close()
    
    # è®¡ç®—ç»Ÿè®¡
    return {
        'mean_reward': np.mean(episode_rewards),
        'std_reward': np.std(episode_rewards),
        'mean_length': np.mean(episode_lengths),
        'std_length': np.std(episode_lengths),
        'success_rate': success_count / num_episodes,
        'num_episodes': num_episodes,
    }


def main():
    """ä¸»å‡½æ•°"""
    
    print("\n" + "="*80)
    print("  BCæ¨¡å‹è¯„ä¼°")
    print("="*80)
    print(f"  Checkpoint: {args.checkpoint}")
    print(f"  å¹¶è¡Œç¯å¢ƒ: {args.num_envs}")
    print(f"  è¯„ä¼°Episodes: {args.num_episodes}")
    print("="*80)
    
    # æ£€æŸ¥checkpointæ˜¯å¦å­˜åœ¨
    checkpoint_path = Path(args.checkpoint)
    if not checkpoint_path.exists():
        raise FileNotFoundError(f"Checkpointä¸å­˜åœ¨: {checkpoint_path}")
    
    # è®¾å¤‡
    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')
    print(f"\nä½¿ç”¨è®¾å¤‡: {device}")
    
    # åŠ è½½æ¨¡å‹
    model, obs_mean, obs_std, action_mean, action_std = load_model(
        checkpoint_path, device
    )
    
    # åˆ›å»ºç¯å¢ƒ
    print("\nåˆ›å»ºè¯„ä¼°ç¯å¢ƒ...")
    env_cfg = ROSOrinEnvCfg()
    env_cfg.scene.num_envs = args.num_envs
    env = ManagerBasedRLEnv(cfg=env_cfg)
    
    # è¯„ä¼°
    results = evaluate(
        env, model, obs_mean, obs_std, action_mean, action_std,
        args.num_episodes, args.max_steps
    )
    
    # æ‰“å°ç»“æœ
    print("\n" + "="*80)
    print("  ğŸ“Š è¯„ä¼°ç»“æœ")
    print("="*80)
    print(f"  Episodes: {results['num_episodes']}")
    print(f"  å¹³å‡å¥–åŠ±: {results['mean_reward']:.2f} Â± {results['std_reward']:.2f}")
    print(f"  å¹³å‡é•¿åº¦: {results['mean_length']:.1f} Â± {results['std_length']:.1f}")
    print(f"  æˆåŠŸç‡: {results['success_rate']*100:.1f}%")
    print("="*80 + "\n")
    
    # å…³é—­ç¯å¢ƒ
    env.close()


if __name__ == "__main__":
    main()
    simulation_app.close()
