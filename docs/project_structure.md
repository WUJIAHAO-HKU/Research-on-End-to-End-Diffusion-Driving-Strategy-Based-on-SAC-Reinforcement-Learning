# é¡¹ç›®ç»“æ„è¯´æ˜

æœ¬æ–‡æ¡£æè¿°é‡æ„åçš„é¡¹ç›®ç›®å½•ç»“æ„å’Œæ¨¡å—ç»„ç»‡ã€‚

## ğŸ“ ç›®å½•ç»“æ„æ¦‚è§ˆ

```
Research on End-to-End Diffusion Driving Strategy Based on SAC Reinforcement Learning/
â”œâ”€â”€ configs/                          # é…ç½®æ–‡ä»¶ç›®å½•
â”‚   â”œâ”€â”€ rewards/                      # ğŸ†• ç®—æ³•ä¸“ç”¨å¥–åŠ±é…ç½®
â”‚   â”‚   â”œâ”€â”€ base_rewards.py          # åŸºç¡€å¥–åŠ±é…ç½®ç±»
â”‚   â”‚   â”œâ”€â”€ ppo_rewards.py           # PPOç®—æ³•å¥–åŠ±é…ç½®
â”‚   â”‚   â”œâ”€â”€ sac_rewards.py           # SACç®—æ³•å¥–åŠ±é…ç½®
â”‚   â”‚   â”œâ”€â”€ bc_rewards.py            # BCç®—æ³•å¥–åŠ±é…ç½®
â”‚   â”‚   â”œâ”€â”€ td3_rewards.py           # TD3ç®—æ³•å¥–åŠ±é…ç½®
â”‚   â”‚   â””â”€â”€ dagger_rewards.py        # DAggerç®—æ³•å¥–åŠ±é…ç½®
â”‚   â”œâ”€â”€ mdp/                          # ğŸ†• MDPå‡½æ•°å®šä¹‰
â”‚   â”‚   â””â”€â”€ rosorin_mdp.py           # è‡ªå®šä¹‰å¥–åŠ±/ç»ˆæ­¢/äº‹ä»¶å‡½æ•°
â”‚   â”œâ”€â”€ env/                          # ç¯å¢ƒé…ç½®
â”‚   â”œâ”€â”€ model/                        # æ¨¡å‹æ¶æ„é…ç½®
â”‚   â””â”€â”€ training/                     # è®­ç»ƒè¶…å‚æ•°é…ç½®
â”‚
â”œâ”€â”€ scripts/                          # ğŸ”„ é‡ç»„åçš„è„šæœ¬ç›®å½•
â”‚   â”œâ”€â”€ training/                     # ğŸ†• è®­ç»ƒè„šæœ¬
â”‚   â”‚   â”œâ”€â”€ train_ppo.py             # PPOè®­ç»ƒ
â”‚   â”‚   â”œâ”€â”€ train_sac_gaussian.py    # SACè®­ç»ƒï¼ˆé«˜æ–¯ç­–ç•¥ï¼‰
â”‚   â”‚   â”œâ”€â”€ train_sac_diffusion.py   # SACè®­ç»ƒï¼ˆæ‰©æ•£ç­–ç•¥ï¼‰
â”‚   â”‚   â”œâ”€â”€ train_bc.py              # BCè®­ç»ƒ
â”‚   â”‚   â”œâ”€â”€ train_td3.py             # TD3è®­ç»ƒ
â”‚   â”‚   â””â”€â”€ train_dagger.py          # DAggerè®­ç»ƒ
â”‚   â”‚
â”‚   â”œâ”€â”€ evaluation/                   # ğŸ†• è¯„ä¼°è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ evaluate_ppo.py          # è¯„ä¼°PPO
â”‚   â”‚   â”œâ”€â”€ evaluate_sac.py          # è¯„ä¼°SAC
â”‚   â”‚   â”œâ”€â”€ evaluate_bc.py           # è¯„ä¼°BC
â”‚   â”‚   â”œâ”€â”€ evaluate_baselines.py    # è¯„ä¼°å•ä¸ªåŸºçº¿
â”‚   â”‚   â”œâ”€â”€ evaluate_all_baselines.py # æ‰¹é‡è¯„ä¼°
â”‚   â”‚   â””â”€â”€ run_baseline_comparison.py # åŸºçº¿å¯¹æ¯”
â”‚   â”‚
â”‚   â”œâ”€â”€ testing/                      # ğŸ†• æµ‹è¯•è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ test_reward_system.py    # æµ‹è¯•å¥–åŠ±ç³»ç»Ÿ
â”‚   â”‚   â”œâ”€â”€ test_reward_extraction.py # æµ‹è¯•å¥–åŠ±æå–
â”‚   â”‚   â”œâ”€â”€ run_rosorin_env.py       # æµ‹è¯•ç¯å¢ƒ
â”‚   â”‚   â””â”€â”€ verify_indoor_scene.py   # éªŒè¯åœºæ™¯é…ç½®
â”‚   â”‚
â”‚   â”œâ”€â”€ data_collection/              # ğŸ†• æ•°æ®æ”¶é›†è„šæœ¬
â”‚   â”‚   â””â”€â”€ collect_mpc_expert_data.py # MPCä¸“å®¶æ•°æ®æ”¶é›†
â”‚   â”‚
â”‚   â”œâ”€â”€ visualization/                # ğŸ†• å¯è§†åŒ–è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ visualize_training.py    # å¯è§†åŒ–è®­ç»ƒè¿‡ç¨‹
â”‚   â”‚   â”œâ”€â”€ visualize_sac_training.py # å¯è§†åŒ–SACè®­ç»ƒ
â”‚   â”‚   â”œâ”€â”€ visualize_bc_policy.py   # å¯è§†åŒ–BCç­–ç•¥
â”‚   â”‚   â”œâ”€â”€ visualize_expert_data.py # å¯è§†åŒ–ä¸“å®¶æ•°æ®
â”‚   â”‚   â””â”€â”€ plot_sac_training.py     # ç»˜åˆ¶SACæ›²çº¿
â”‚   â”‚
â”‚   â”œâ”€â”€ analysis/                     # ğŸ†• åˆ†æè„šæœ¬
â”‚   â”‚   â””â”€â”€ analyze_sac_cases.py     # åˆ†æSACæ¡ˆä¾‹
â”‚   â”‚
â”‚   â”œâ”€â”€ utils/                        # ğŸ†• å·¥å…·è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ path_generator.py        # è·¯å¾„ç”Ÿæˆå™¨
â”‚   â”‚   â”œâ”€â”€ simple_path_generator.py # ç®€å•è·¯å¾„ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ indoor_scene_aware_path_generator.py # å®¤å†…è·¯å¾„ç”Ÿæˆ
â”‚   â”‚   â”œâ”€â”€ mpc_controller.py        # MPCæ§åˆ¶å™¨
â”‚   â”‚   â”œâ”€â”€ fix_reward_extraction.py # ä¿®å¤è„šæœ¬
â”‚   â”‚   â”œâ”€â”€ urdf_to_usd.py          # æ ¼å¼è½¬æ¢
â”‚   â”‚   â””â”€â”€ ...
â”‚   â”‚
â”‚   â”œâ”€â”€ deployment/                   # ğŸ†• éƒ¨ç½²è„šæœ¬
â”‚   â”‚   â””â”€â”€ deploy_to_robot.py       # çœŸæœºéƒ¨ç½²
â”‚   â”‚
â”‚   â”œâ”€â”€ env_factory.py               # ğŸ†• ç¯å¢ƒé…ç½®å·¥å‚
â”‚   â””â”€â”€ rosorin_env_cfg.py           # åŸºç¡€ç¯å¢ƒé…ç½®ï¼ˆä¸å«å¥–åŠ±ï¼‰
â”‚
â”œâ”€â”€ src/                              # æºä»£ç æ¨¡å—
â”‚   â”œâ”€â”€ algorithms/                   # ç®—æ³•å®ç°
â”‚   â”œâ”€â”€ baselines/                    # åŸºçº¿ç®—æ³•
â”‚   â”œâ”€â”€ models/                       # ç¥ç»ç½‘ç»œæ¨¡å‹
â”‚   â””â”€â”€ envs/                         # ç¯å¢ƒå°è£…
â”‚
â”œâ”€â”€ experiments/                      # å®éªŒç»“æœ
â”‚   â”œâ”€â”€ baseline_comparison/          # åŸºçº¿å¯¹æ¯”ç»“æœ
â”‚   â”œâ”€â”€ checkpoints/                  # æ¨¡å‹æ£€æŸ¥ç‚¹
â”‚   â”œâ”€â”€ logs/                         # è®­ç»ƒæ—¥å¿—
â”‚   â””â”€â”€ tensorboard/                  # TensorBoardæ—¥å¿—
â”‚
â””â”€â”€ docs/                             # æ–‡æ¡£
    â”œâ”€â”€ TRAINING_WORKFLOW.md          # è®­ç»ƒå·¥ä½œæµ
    â”œâ”€â”€ PROJECT_STRUCTURE.md          # æœ¬æ–‡ä»¶
    â””â”€â”€ ...

```

## ğŸ¯ è®¾è®¡ç†å¿µ

### 1. **å¥–åŠ±é…ç½®è§£è€¦** ğŸ†•

**é—®é¢˜**: ä¹‹å‰æ‰€æœ‰ç®—æ³•å…±ç”¨ä¸€ä¸ªå¥–åŠ±é…ç½®ï¼ˆ`rosorin_env_cfg.py`ï¼‰ï¼Œä¸åŒç®—æ³•æ— æ³•ä¼˜åŒ–å„è‡ªçš„å¥–åŠ±æƒé‡ã€‚

**è§£å†³æ–¹æ¡ˆ**: 
- åˆ›å»º `configs/rewards/` ç›®å½•
- æ¯ä¸ªç®—æ³•æœ‰ç‹¬ç«‹çš„å¥–åŠ±é…ç½®æ–‡ä»¶
- é€šè¿‡ `env_factory.py` å·¥å‚å‡½æ•°åŠ¨æ€åˆ›å»ºç¯å¢ƒ

**ç¤ºä¾‹**:
```python
# PPOè®­ç»ƒè„šæœ¬
from env_factory import create_ppo_env_cfg

env_cfg = create_ppo_env_cfg(num_envs=8)
# è‡ªåŠ¨ä½¿ç”¨PPOä¸“ç”¨çš„å¥–åŠ±æƒé‡é…ç½®
```

### 2. **è„šæœ¬åŠŸèƒ½åˆ†ç±»** ğŸ”„

**é—®é¢˜**: ä¹‹å‰æ‰€æœ‰è„šæœ¬æ··åœ¨ `scripts/` æ ¹ç›®å½•ï¼Œéš¾ä»¥å®šä½å’Œç»´æŠ¤ã€‚

**è§£å†³æ–¹æ¡ˆ**: æŒ‰åŠŸèƒ½åˆ†ç±»åˆ°å­ç›®å½•ï¼š
- `training/` - è®­ç»ƒè„šæœ¬ï¼ˆæ‰§è¡Œé¢‘ç‡é«˜ï¼‰
- `evaluation/` - è¯„ä¼°è„šæœ¬ï¼ˆå¯¹æ¯”ä¸åŒæ¨¡å‹ï¼‰
- `testing/` - æµ‹è¯•è„šæœ¬ï¼ˆè°ƒè¯•ç¯å¢ƒå’Œç³»ç»Ÿï¼‰
- `visualization/` - å¯è§†åŒ–è„šæœ¬ï¼ˆç»˜å›¾å’Œåˆ†æï¼‰
- `data_collection/` - æ•°æ®æ”¶é›†è„šæœ¬ï¼ˆç”Ÿæˆä¸“å®¶æ•°æ®ï¼‰
- `utils/` - å·¥å…·è„šæœ¬ï¼ˆè¾…åŠ©åŠŸèƒ½ï¼‰
- `deployment/` - éƒ¨ç½²è„šæœ¬ï¼ˆçœŸæœºè¿è¡Œï¼‰

### 3. **MDPå‡½æ•°é›†ä¸­ç®¡ç†** ğŸ†•

**é—®é¢˜**: `rosorin_mdp.py` æ··åœ¨scriptsç›®å½•ï¼Œä¸æ˜“äºé…ç½®å¼•ç”¨ã€‚

**è§£å†³æ–¹æ¡ˆ**:
- ç§»åŠ¨åˆ° `configs/mdp/rosorin_mdp.py`
- æ‰€æœ‰å¥–åŠ±é…ç½®ç»Ÿä¸€ä»è¿™é‡Œå¯¼å…¥MDPå‡½æ•°

## ğŸ“– ä½¿ç”¨æŒ‡å—

### è®­ç»ƒæ¨¡å‹

```bash
# PPOè®­ç»ƒï¼ˆä½¿ç”¨PPOä¸“ç”¨å¥–åŠ±é…ç½®ï¼‰
./isaaclab_runner.sh scripts/training/train_ppo.py --num_envs 8 --total_steps 100000

# SACè®­ç»ƒï¼ˆä½¿ç”¨SACä¸“ç”¨å¥–åŠ±é…ç½®ï¼‰
./isaaclab_runner.sh scripts/training/train_sac_gaussian.py --num_envs 8

# BCè®­ç»ƒï¼ˆä½¿ç”¨BCä¸“ç”¨å¥–åŠ±é…ç½®ï¼‰
./isaaclab_runner.sh scripts/training/train_bc.py --demo_path data/demonstrations/mpc_expert.pkl
```

### è¯„ä¼°æ¨¡å‹

```bash
# è¯„ä¼°PPOæ¨¡å‹
./isaaclab_runner.sh scripts/evaluation/evaluate_ppo.py --checkpoint experiments/baselines/ppo/model.pth

# æ‰¹é‡è¯„ä¼°æ‰€æœ‰åŸºçº¿
./isaaclab_runner.sh scripts/evaluation/evaluate_all_baselines.py
```

### æµ‹è¯•ç¯å¢ƒ

```bash
# æµ‹è¯•å¥–åŠ±ç³»ç»Ÿ
./isaaclab_runner.sh scripts/testing/test_reward_system.py

# éªŒè¯åœºæ™¯é…ç½®
./isaaclab_runner.sh scripts/testing/verify_indoor_scene.py
```

### å¯è§†åŒ–ç»“æœ

```bash
# ç»˜åˆ¶SACè®­ç»ƒæ›²çº¿
python scripts/visualization/plot_sac_training.py --log_dir experiments/sac_training/logs

# å¯è§†åŒ–BCç­–ç•¥
./isaaclab_runner.sh scripts/visualization/visualize_bc_policy.py --checkpoint model.pth
```

## ğŸ”§ è‡ªå®šä¹‰å¥–åŠ±é…ç½®

å¦‚æœéœ€è¦ä¸ºæ–°ç®—æ³•åˆ›å»ºä¸“ç”¨å¥–åŠ±é…ç½®ï¼š

1. **åˆ›å»ºæ–°çš„å¥–åŠ±é…ç½®æ–‡ä»¶**:
```python
# configs/rewards/my_algorithm_rewards.py
from isaaclab.managers import RewardTermCfg as RewTerm
from isaaclab.utils import configclass
import isaaclab.envs.mdp as mdp
import sys, os

mdp_path = os.path.abspath(os.path.join(os.path.dirname(__file__), '../mdp'))
if mdp_path not in sys.path:
    sys.path.insert(0, mdp_path)
import rosorin_mdp

@configclass
class MyAlgorithmRewardsCfg:
    progress = RewTerm(func=rosorin_mdp.progress_reward, weight=25.0)
    # ... å…¶ä»–å¥–åŠ±é…ç½®
```

2. **åœ¨env_factory.pyä¸­æ·»åŠ å·¥å‚å‡½æ•°**:
```python
def create_my_algorithm_env_cfg(num_envs=8, env_spacing=5.0):
    from configs.rewards.my_algorithm_rewards import MyAlgorithmRewardsCfg
    from rosorin_env_cfg import ROSOrinEnvCfg
    
    env_cfg = ROSOrinEnvCfg()
    env_cfg.scene.num_envs = num_envs
    env_cfg.scene.env_spacing = env_spacing
    env_cfg.rewards = MyAlgorithmRewardsCfg()
    
    return env_cfg
```

3. **åœ¨è®­ç»ƒè„šæœ¬ä¸­ä½¿ç”¨**:
```python
from env_factory import create_my_algorithm_env_cfg

env_cfg = create_my_algorithm_env_cfg(num_envs=8)
env = ManagerBasedRLEnv(cfg=env_cfg)
```

## ğŸ“ ç®—æ³•ä¸“ç”¨å¥–åŠ±é…ç½®å¯¹æ¯”

| ç®—æ³• | ä¸»å¯¼èˆªæƒé‡ (progress+orientation+velocity) | æƒ©ç½šæƒé‡ | è®¾è®¡æ€è·¯ |
|------|-------------------------------------------|---------|----------|
| **PPO** | 28.0 (20+5+3) | 4.6 | é«˜å¯†é›†å¥–åŠ±ï¼Œé¼“åŠ±æ¢ç´¢ |
| **SAC** | 24.5 (18+4+2.5) | 7.3 | å¹³è¡¡æ¢ç´¢åˆ©ç”¨ï¼Œåˆ©ç”¨ç»éªŒå›æ”¾ |
| **TD3** | 23.5 (17+4+2.5) | 8.5 | æ›´ä¿å®ˆï¼Œæ³¨é‡åŠ¨ä½œå¹³æ»‘ |
| **BC** | 20.0 (15+3+2) | 10.5 | åŸºç¡€é…ç½®ï¼Œç”¨äºè¯„ä¼° |
| **DAgger** | 20.0 (15+3+2) | 10.5 | ä¸BCä¸€è‡´ï¼Œè¿­ä»£å­¦ä¹  |

## ğŸ“ é‡è¦å˜æ›´

### âœ… å·²å®Œæˆ

1. âœ… åˆ›å»º `configs/rewards/` ç›®å½•å’Œå„ç®—æ³•å¥–åŠ±é…ç½®
2. âœ… ç§»åŠ¨ `rosorin_mdp.py` åˆ° `configs/mdp/`
3. âœ… é‡ç»„ `scripts/` ä¸ºåŠŸèƒ½ç›®å½•
4. âœ… åˆ›å»º `env_factory.py` å·¥å‚æ¨¡å—
5. âœ… æ›´æ–° `train_ppo.py` ä½¿ç”¨æ–°é…ç½®
6. âœ… è§£å†³å¾ªç¯å¯¼å…¥é—®é¢˜
7. âœ… æµ‹è¯•è®­ç»ƒè„šæœ¬æ­£å¸¸è¿è¡Œ

### âš ï¸ éœ€è¦æ³¨æ„

1. **å¯¼å…¥é¡ºåº**: å¥–åŠ±é…ç½®å¿…é¡»åœ¨ `AppLauncher` å¯åŠ¨åå¯¼å…¥
2. **è·¯å¾„æ›´æ–°**: æ‰€æœ‰è®­ç»ƒè„šæœ¬è·¯å¾„ä» `scripts/train_*.py` æ”¹ä¸º `scripts/training/train_*.py`
3. **å‘åå…¼å®¹**: `scripts/rosorin_env_cfg.py` å’Œ `scripts/rosorin_mdp.py` ä»ä¿ç•™ï¼Œå¯ç”¨äºæ—§è„šæœ¬

## ğŸš€ åç»­ä¼˜åŒ–å»ºè®®

1. **ç¯å¢ƒé…ç½®æ¨¡å—åŒ–**: å°†åœºæ™¯ã€ä¼ æ„Ÿå™¨ã€æœºå™¨äººé…ç½®è¿›ä¸€æ­¥åˆ†ç¦»
2. **è¶…å‚æ•°é…ç½®æ–‡ä»¶**: ä¸ºæ¯ä¸ªç®—æ³•åˆ›å»ºYAMLé…ç½®æ–‡ä»¶
3. **å®éªŒç®¡ç†ç³»ç»Ÿ**: ä½¿ç”¨MLflowæˆ–Weights&Biasesè¿½è¸ªå®éªŒ
4. **å•å…ƒæµ‹è¯•**: ä¸ºå…³é”®æ¨¡å—æ·»åŠ æµ‹è¯•ç”¨ä¾‹
5. **CI/CD**: è‡ªåŠ¨åŒ–æµ‹è¯•å’Œéƒ¨ç½²æµç¨‹

---

**æ›´æ–°æ—¥æœŸ**: 2025å¹´12æœˆ30æ—¥  
**é‡æ„ç‰ˆæœ¬**: v2.0  
**ç»´æŠ¤è€…**: ROSOriné¡¹ç›®å›¢é˜Ÿ
